# 名词解释

## 模型

    类似于一个大脑, 大脑中带有很多功能, 比如说: 分词,逻辑推理 等

### 模型分类

#### 根据处理方向分类

1. LLM: 大语言模型, 用来处理自然语言, 如: ChatGPT,LLaMA,Qwen,BERT,RoBERTa 等
2. VLM: 视觉语言模型, 能处理图像+语言的模型, 如: CLIP,BLIP,MiniGPT-4 等

#### 根据训练程度分类

1. 空白模型, 需要从头进行大量的数据训练, 否则啥也不懂
2. 预训练模型(如 BERT,GPT 等), 已经在海量文本中训练过, 会 语言表达,推理,QA 等
3. 微调后的模型(如 uer/roberta-qa), 有针对性的能力, 例如专门擅长 中文问答,NER,翻译 等

### 模型训练

    像 GPT,BERT,BART,T5 这些都被训练为语言模型, 这意味着它们已经以无监督学习的方式接受了大量原始文本的训练.
    无监督学习是一种训练类型, 其中目标是模型根据输入自动计算, 这意味着不需要人工来标记数据.
    这种类型的模型可以对其训练过的语言有统计学的理解, 但对于特定的实际任务的效果并不是很好.
    因此, 一般的预训练模型会经历一个成为迁移学习(transfer learning)的过程, 在这个过程中, 模型在给定任务上以监督方式(即 使用人工注释标签)进行微调.

#### 模型训练的过程

##### 1. 预训练(Pretraining)

    在超大规模语料上(比如 Wikipedia,新闻,书籍)训练模型, 不针对任何具体任务, 只针对语言(中文,英文 等)本身.
    这是模型最初的学习阶段, 训练时间非常久(可能需要几周甚至几个月).
    目的是让模型掌握 语言结构,语义,句法 等能力, 这就像人从小听别人说话, 掌握 语感,句法 等.
    过程中虽然看到了很多内容, 但并不会有意识的记住这些内容, 更像是在潜意识中建立了对语言的 "统计性理解"和"逻辑建模" 的能力.
    大概理解就是 "只是把逻辑保留下来, 而不会存储大多数的内容", 但也不是绝对的, 因为训练本身就用到了很多知识性文本, 虽然它不是 "逐字记忆",
    但在语言建模的过程中, 很多知识就以 "语义和统计特征" 的方式 "嵌入" 到了参数中, 所以有时候模型虽然没有专门训练过也能回答一些冷门知识.
    但如果想让模型 更精确,可控的记住和回答某些问题, 那么就必须用 "微调" 来重点强化.

##### 2. 迁移学习 / 微调(Fine-tuning)

    用少量标注数据告诉模型, 现在要具体干的事情, 比如告诉模型, 当你看到 "A" 这个问题, "B" 就是正确答案
    类似于往模型的知识库中录入很多问题和答案, 目标是告诉模型, 当你看到某个问题(或相似的问题)就直接回答这个答案(或者根据这个答案来重新组织语言进行回答)

#### 掩码(masking)

    在训练的过程中, transformers 的架构体系中有一个掩码的概念, 以下通过训练一个中英文翻译机器人的例子来举例:

    输入 -> "我是一个学生", 输出 -> "I am a student"

    假设我们想以上面这个问答对来对我们的模型进行训练, 
    1. 首先将问答对以指定的格式导入到模型中(或者存放到某个文件中)
    2. 编码器会先将输入进行 分词和嵌入向量, 最终结果像是: [[向量1], [向量2], [向量3], [向量4]].
    3. 编码器的注意力机制, 编码器的注意力层可以让每个词看到句子中的其它词, 比如 "我" 能感知 "学生", 建立更全面的上下文理解
    4. 编码器的最终结果会给到解码器, 注意, 现在模型已经知道了具体答案, 但我们现在是在训练的过程中, 所以我们不能把具体的答案告诉模型, 不然模型就会偷懒(偷看答案), 模型会直接把结果返回出来
    5. 所以解码器的注意力机制控制, 模型只能看到编码器的结果, 以及他当前预测完的结果, 强制要求他一步一步自己生成结果, 比如当他预测翻译出第一个单词 "I" 之后, 他能看到的内容是 编码器的结果和"I"
    6. 当编码器预测翻译出第二个单词是 "am" 后, 它能看到的内容是 编码器的结果和 "I"以及"am"
    7. 通过这种方式, 强迫模型去自己推导预测出结果
    8. 当模型预测出结果后会去跟标准答案对比(计算与正确答案之间的差距)
    9. 如果预测的结果与标准答案差距太大, 模型会使用 "反向传播(backpropagation)" 算法调整参数, 并记住这次预测是错误的, 下次尽量不会再犯

    以上过程发生在训练阶段

#### 偏见和局限性

    虽然很多预训练模型非常强大, 但他们也有局限性.
    其中最大的一个问题是, 为了对大量数据进行预训练, 研究人员通常会搜集所有他们能找到的所有文字内容, 中间可能夹带一些意识形态或者价值观的刻板印象. 
    比如我们让模型分别回答 男人的职业和女人的职业 两个回答, 模型的回答可能会带有与性别有关的特殊职业, 如下
    
    男人: [“律师”、“木匠”、“医生”、“服务员”、“机械师”]
    女人: [“护士”、“服务员”、“老师”、“女佣”、“妓女”]

    在使用的原始模型的时候, 很容易生成 性别歧视,种族主义或恐同内容. 这种固有偏见不会随着微调模型而使消失.

## PyTorch | TensorFlow | JAX

    模型开发和执行的底层平台, 提供 张量,自动求导,训练循环 等能力, 类似于 java 中的 JVM+Java语法+多线程库 

### 张量(tensor)

    一种基于数组或列表封装的数据类型(结构), 类似于一个多维数组(实际上张量的纬度限制是 >= 0, 但是 >= 2 的更常见).
    张量是深度学习框架(如: PyTorch,TensorFlow)中用于高效数值计算的一种特殊的多维数组容器.
    张量必须要经过填充, 确保每一项的对应纬度长度一致, 若未被填充(即纬度不一致)则不能被称为张量.
    GPU 更擅长处理 "规则的矩形数组", 因为可以并行的处理 加法,乘法 等操作

    更严格的数学定义如下:
    0维张量：一个数（标量），如 3.14
    1维张量：向量 [1, 2, 3]
    2维张量：矩阵 [[1, 2], [3, 4]]
    3维张量：矩阵序列（比如 [batch_size, seq_len, embedding_dim]）
    4维张量：图像输入 [batch_size, channels, height, width]

### 梯度(grad)

    定义: 函数在某一点的 导数 或 偏导数", 也就是: 函数在当前位置往哪个方向走, 会让结果变小(或变大)最快.
    
    假设我们现在站在山坡某处, 闭着眼, 如何依靠脚下的斜率快速找到山谷中的最低点?
    这个 "脚下感受到的各个方向的斜率" 就是梯度.

    数学定义:
    比如我们有一个函数
    y = f(x)
    x 的取值范围为 [x1, x2, x3, ..., xn]
    现在当我们位于 x3 上, 该往哪个方向移动参数, 能最快让函数 f 的结果变小(或变大)?

    总结: 梯度是告诉你 "怎么改参数能让模型变得更好" 的方向指引器

### 向前传播(forward)

    模型从输入算到输出:
    比如输入 input_ids -> 模型 -> 输出 logits(分数) -> loss

### 反向传播(backward)

    根据 loss 的值, 自动计算所有参数对 loss 的梯度
    用的是链式法则(自动微分)